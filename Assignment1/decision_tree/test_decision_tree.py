"""
decision tree test
"""

import pandas as pd
from decision_tree import DecisionTreeClassifier
from viz_tree import plot_tree
import matplotlib.pyplot as plt
from pathlib import Path
import numpy as np

def test_dt_classification():
    # Load iris train/test CSV generated by iris_download.py
    data_dir = Path(__file__).parent / 'dataset'
    train_path = data_dir / 'iris_train.csv'
    test_path = data_dir / 'iris_test.csv'

    output_dir = Path(__file__).parent / 'output'
    output_dir.mkdir(exist_ok=True)

    if not train_path.exists() or not test_path.exists():
        raise FileNotFoundError("iris_train.csv / iris_test.csv not found. Run iris_download.py first.")

    df_train = pd.read_csv(train_path)
    df_test = pd.read_csv(test_path)

    feature_names = list(df_train.columns[:-1])
    X = df_train[feature_names].to_numpy(dtype=float)
    y = df_train['label'].to_numpy(dtype=int)
    X_test = df_test[feature_names].to_numpy(dtype=float)
    y_test = df_test['label'].to_numpy(dtype=int)

    # 参数范围设置
    max_depths = range(3, 7)
    min_samples_splits = range(2, 5)
    max_features_list = [2, 3, 4]
    min_impurity_splits = [0.0, 0.01, 0.05, 0.025, 0.075, 0.1]
    splitters = ["best", "random"]
    criteria = ["info_gain", "info_gain_ratio", "gini", "error_rate"]
    
    best_acc = 0
    best_params = None
    
    while best_acc < 1.0:
        # 随机选择参数
        max_depth = 6
        min_samples_split = 3
        max_features = 2
        min_impurity_split = 0.075
        splitter = 'random'
        criterion = 'error_rate'
        
        # 训练模型
        dt_clf = DecisionTreeClassifier(
            criterion=criterion,
            splitter=splitter,
            max_depth=max_depth,
            max_features=max_features,
            min_impurity_split=min_impurity_split,
            min_samples_split=min_samples_split,
            random_state= None
        )
        
        dt_clf.fit(X, y)
        preds = dt_clf.predict(X_test)
        acc = (preds == y_test).mean()
        
        print(f"Current accuracy: {acc:.4f} with params:")
        print(f"max_depth={max_depth}, min_samples_split={min_samples_split}")
        print(f"max_features={max_features}, min_impurity_split={min_impurity_split:.4f}")
        print(f"splitter={splitter}, criterion={criterion}\n")
        
        if acc > best_acc:
            best_acc = acc
            best_params = {
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'max_features': max_features,
                'min_impurity_split': min_impurity_split,
                'splitter': splitter,
                'criterion': criterion
            }
            
            # 保存最佳模型的图
            fig, ax = plot_tree(
                dt_clf,
                feat_names=feature_names,
                class_names=["0", "1", "2"],
                show_split_score=True,
                show_leaf_samples=True,
                top_padding=0.18
            )
            ax.set_title(f"Decision Tree (acc={acc:.4f})")
            plt.savefig(f"{output_dir}/iris_best.png")
            plt.close()

    print("\nFound perfect accuracy!")
    print("Best parameters:", best_params)

if __name__ == '__main__':
    test_dt_classification()